# 深度模型中的优化
### 目录  
+ [应用数学与数学基础](../应用数学与数学基础/ "../应用数学与数学基础/") 
    + [线性代数](../应用数学与数学基础/线性代数.md "../应用数学与数学基础/线性代数.md")
    + [概率与信息论](../应用数学与数学基础/概率与信息论.md "../应用数学与数学基础/概率与信息论.md") 
    + [数值计算](../应用数学与数学基础/数值计算.md "../应用数学与数学基础/数值计算.md")
    + [机器学习基础](../应用数学与数学基础/机器学习基础.md "../应用数学与数学基础/机器学习基础.md")
+ [深度网络:现代实践](../深度网络：现代实践/ "../深度网络：现代实践/")
    + [深度前馈网络](../深度网络：现代实践/深度前馈网络.md "../深度网络：现代实践/深度前馈网络.md")
    + [深度学习中的正则化](../深度网络：现代实践/深度学习中的正则化.md "../深度网络：现代实践/深度学习中的正则化.md")
    + [**深度模型中的优化**](../深度网络：现代实践/深度模型中的优化.md "../深度网络：现代实践/深度模型中的优化.md")
    + [卷积网络](../深度网络：现代实践/卷积网络.md "../深度网络：现代实践/卷积网络.md")
    + [序列建模:循环和递归网络](../深度网络：现代实践/序列建模：循环和递归网络.md "../深度网络：现代实践/序列建模：循环和递归网络.md")
    + [实践方法论](../深度网络：现代实践/实践方法论.md "../深度网络：现代实践/实践方法论.md")
    + [应用](../深度网络：现代实践/应用.md "../深度网络：现代实践/应用.md")
+ [深度学习研究](../深度学习研究/ "../深度学习研究/")
    + [线性因子模型](../深度学习研究/线性因子模型.md "../深度学习研究/线性因子模型.md")
    + [自编码器](../深度学习研究/自编码器.md "../深度学习研究/自编码器.md")
    + [表示学习](../深度学习研究/表示学习.md "../深度学习研究/表示学习.md")
    + [深度学习中的结构化概率模型](../深度学习研究/深度学习中的结构化概率模型.md "../深度学习研究/深度学习中的结构化概率模型.md")
    + [蒙特卡罗方法](../深度学习研究/蒙特卡罗方法.md "../深度学习研究/蒙特卡罗方法.md")
    + [直面配分函数](../深度学习研究/直面配分函数.md "../深度学习研究/直面配分函数.md")
    + [近似推断](../深度学习研究/近似推断.md "../深度学习研究/近似推断.md")
    + [深度生成模型](../深度学习研究/深度生成模型.md "../深度学习研究/深度生成模型.md")

## 前言
　　本文主要介绍神经网络训练中的优化技术，兵主要关注一类特定的优化问题：寻找神经网络上的一组参数θ，它能显著地降低代价函数J(θ)，
该代价函数通常包括整个训练集上的性能评估和额外的正则化项。  
　　本文首先会介绍机器学习任务中作为训练算法使用的优化与纯优化有哪些不同；其次，会介绍导致神经网络优化困难的几个具体挑战；然后，
会介绍几个使用算法，包括优化算法本身和初始化参数的策略，包括更高级的可以自适应调整学习率和使用二阶导数的信息的算法；最后，
将介绍几个简单优化算法结合成高级过程的优化策略。
## 深度模型训练的优化算法和传统优化算法的不同
　　在大多数的机器学习问题上，我们只关注某些性能度量P，P定义于测试集上并且可能是不可解的，这导致我们只能间接优化P。而纯优化是最小化目标J本身。
通常来讲，代价函数可写为训练集上的平均，更进一步的是希望最小化取自数据生成分布p<sub>data</sub>的期望，其公式如下所示　　
<div align=center name="(1-1)"><img src="https://latex.codecogs.com/gif.latex?J^{*}(\theta)=\mathbb{E}_{\left&space;(&space;x,y&space;\right&space;)\sim&space;p_{data}}L\left&space;(&space;f\left&space;(&space;x;\theta&space;\right&space;),&space;y&space;\right&space;)" title="J^{*}(\theta)=\mathbb{E}_{\left ( x,y \right )\sim p_{data}}L\left ( f\left ( x;\theta \right ), y \right )" /><div align=right>(1-1)</div></div>

### 经验风险最小化
　　机器算法的目标是降低[代价函数](#(1-1))的期望泛化误差，这样的误差我们称之为风险，而通常我们是无法知道p<sub>data</sub>(x,y)的，
只能知道训练集中的样本。而将机器学习问题转化会一个优化问题的最简单方法是最小化训练集上的期望损失，这意味着我们必须用训练集上的经验分布
<a><img src="https://latex.codecogs.com/gif.latex?\widehat{p}\left(&space;x,y\right)" title="\widehat{p}\left( x,y\right)" /></a>
替代真实分布p(x,y)，进而最小化经验风险：  
<div align=center><img src="https://latex.codecogs.com/gif.latex?\mathbb{E}_{x,y\sim&space;\widehat{p}_{data}}\left&space;[&space;L&space;\left&space;(&space;f\left&space;(&space;x;\theta&space;\right&space;),&space;y&space;\right&space;)\right&space;]=\frac{1}{m}\sum_{i=1}^{m}L\left&space;(&space;f\left&space;(&space;x^{i};\theta&space;\right&space;),&space;y^{i})&space;\right&space;)" title="\mathbb{E}_{x,y\sim \widehat{p}_{data}}\left [ L \left ( f\left ( x;\theta \right ), y \right )\right ]=\frac{1}{m}\sum_{i=1}^{m}L\left ( f\left ( x^{i};\theta \right ), y^{i}) \right )" /><div align=right>(1-2)</div></div>  
但是经验风险最小化容易导致过拟合，此外，很多情况下，经验风险最小化并不一定可行的，比如对于0-1损失函数根据经验风险最小化是没有有效导数的。

### 代理损失函数和提前终止
　　正如上面所说的，有时候真正的损失函数并不能被高效优化，这种情况下，我们通常会去优化其代理损失函数，比如0-1损失函数，我们不能直接有效优化，
但是可以通过正确列别的负对数似然函数来代替0-1损失函数。在某些情况下，代理损失函数要比原损失函数学到的更多。一般的优化和用于训练算法的优化的
一个重要的不同是训练算法通常不会停止在局部极小点，但是在基于提前终止([深度学习中的正则化-提前终止](/深度学习中的正则化.md))的收敛条件满足时停止

### 第三方
###第三方
### 第三方
###第三方
### 第三方
###第三方
### 第三方
###第三方
### 第三方
###第三方
### 第三方
###第三方
### 第三方
###第三方### 第三方
###第三方### 第三方
###第三方
### 第三方
###第三方
[代价函数](#(1-1))



